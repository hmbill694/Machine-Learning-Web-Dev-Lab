{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "def convert_from_sklearn_to_data_frame(in_data_set):\n",
    "    data_set = in_data_set\n",
    "    df = pd.DataFrame(data_set.data,columns=data_set.feature_names)\n",
    "    df.target = pd.Series(data_set.target)\n",
    "    return df\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"This is the activation function for the network, it will\n",
    "        squishify the results of the network to be between 0 and 1.\n",
    "        It is non-linear  like all other activation functions\"\"\"\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"This is the \"derivative\" of the sigmoid function. \n",
    "        it will be used in the learning phase of the network. \n",
    "        The real derivative of the sigmoid function is\n",
    "        f'(x) = sigmoid(x) x (1- sigmoid(x)). However\n",
    "        when using this in the program my values have already\n",
    "        gone through the sigmoid function so doing so again would be\n",
    "        incorrect\"\"\"\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "\n",
    "def create_weight_matrix_for_layer(num_neurons_in_next_layer,\n",
    "                                   num_neurons_in_current_layer):\n",
    "    \"\"\"This will create a matrix with random values of the shape \n",
    "        R x C where R = the number of neurons in the next layer\n",
    "        and C = the number of neurons in the current layer\"\"\"\n",
    "\n",
    "    return np.random.randn(num_neurons_in_next_layer,num_neurons_in_current_layer)\n",
    "\n",
    "def create_weight_matrix_for_network(network_architecture):\n",
    "    \"\"\"This function will create the weight matrix for an entire network\n",
    "        it takes a list where each member in the list represents the the number\n",
    "        of neurons in that layer. So a input of [5,2,1] represents a network\n",
    "        with 5 neurons in the first layer, 2 in the second and one in the last layer.\n",
    "        It will return a list of n-dimensional numpy arrays where each entry in the list\n",
    "        represents the weights from one layer to the next\"\"\"\n",
    "    \n",
    "    # Okay so what's this slicing about? For the architecture of a network we are able to \n",
    "    # deduce the overall structure of the weight matrix. We will have n-1 weight layers \n",
    "    # per network where n is the total number of network layers. There are no weights for \n",
    "    # incoming data so a network shaped like [5,2,1] will have 2 weight layers. \n",
    "    # The first weight layer will be an array with two rows and 5 columns, the second\n",
    "    # 1 row with 2 columns\n",
    "    column_values = network_architecture[:-1]\n",
    "    row_values = network_architecture[1:]\n",
    "    \n",
    "    return [create_weight_matrix_for_layer(row,col) for row, col in zip(row_values, column_values)]\n",
    "\n",
    "def create_biases_for_layer(num_neurons_in_layer):\n",
    "    \"\"\"Creates a np matrix of (n x 1) for a layer of a network\n",
    "        returns the matrix \"\"\"\n",
    "    return np.random.randn(num_neurons_in_layer,1)\n",
    "\n",
    "def create_bias_matrix_for_network(network_architecture):\n",
    "    \"\"\"The number of bias matrices for a network is n - 1, where\n",
    "        no is the number of layers in the network, including inputs.\n",
    "        Each neuron in a layer will have it's own bias. So a network \n",
    "        of size [5,2,1] will have two biases for one layer and 1 for the next.\n",
    "        The inputs do not get biases.\"\"\"\n",
    "    layers_that_need_biases = network_architecture[1:]\n",
    "    return [create_biases_for_layer(neurons_in_layer) for neurons_in_layer in layers_that_need_biases ]\n",
    "    \n",
    "\n",
    "def create_error_matrix(weight_matrix, actual_values_matrix, guessed_values_matrix):\n",
    "    \"\"\"Calculates the error matrix for all hidden layers plus the ouput\n",
    "        returns a list where the error at the output is the first element\n",
    "        and the last element is the \"\"\"\n",
    "    actual_values_matrix = np.c_[actual_values_matrix]\n",
    "    guessed_values_matrix = np.c_[guessed_values_matrix]\n",
    "    \n",
    "    # seed error with error between output of network and target output \n",
    "    error = [np.subtract(actual_values_matrix, guessed_values_matrix)]\n",
    "    \n",
    "    # Reverse the weight matrix and then iterate in reverse to\n",
    "    # the last layer, we omit the first layer as that would calculate \n",
    "    # the error for inputs which does not make sense\n",
    "    for index, layer in enumerate(weight_matrix[:0:-1]):\n",
    "        error.append(np.dot(layer.transpose(), error[index]))\n",
    "        \n",
    "    return error\n",
    "    \n",
    "def back_propagation():\n",
    "    pass\n",
    "\n",
    "def train_network(inputs, weight_matrix, ):\n",
    "    pass\n",
    "\n",
    "def feed_forward(input_matrix_as_list, network_weight_matrix, network_bias_matrix):\n",
    "    \"\"\"This function feeds the inputs into the matrix.\"\"\"\n",
    "    # Store inputs as a column matrix (n x 1)\n",
    "    input_matrix = np.c_[input_matrix_as_list]\n",
    "    layer_activations = []\n",
    "    for bias, weight in zip(network_bias_matrix, network_weight_matrix):\n",
    "        input_matrix = sigmoid(np.dot(weight,input_matrix ) + bias)\n",
    "        layer_activations.append(input_matrix)\n",
    "    return input_matrix, layer_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Weight matrix  [array([[ 0.48823604, -0.57325709, -0.12339236, -0.11846737, -1.04811766],\n",
      "       [-0.71431381, -0.5313108 ,  0.06435784,  0.59037912, -0.47562506]]), array([[ 1.96379668, -0.01047229],\n",
      "       [-0.24929351,  1.51785369]]), array([[1.82249114, 1.4422142 ]])] \n",
      "\n",
      "Bias matrix  [array([[-1.29844537],\n",
      "       [-1.50320491]]), array([[0.49121223],\n",
      "       [0.66858081]]), array([[0.27098907]])] \n",
      "\n",
      "Activations:  [array([[0.00032177],\n",
      "       [0.04295589]]), array([[0.62043483],\n",
      "       [0.67561698]]), array([[0.91498737]])]\n",
      "Final Output:  [[0.91498737]]\n",
      "[array([[0.08501263]]), array([[0.15493476],\n",
      "       [0.12260642]]), array([[0.27369538],\n",
      "       [0.18447608]])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "practice = [5,2,2,1]\n",
    "\n",
    "\n",
    "biases = create_bias_matrix_for_network(practice)\n",
    "weights = create_weight_matrix_for_network(practice)\n",
    "# \n",
    "print(\"Weight matrix \", weights, \"\\n\")\n",
    "print(\"Bias matrix \", biases, \"\\n\")\n",
    "# \n",
    "# \n",
    "a = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "# \n",
    "# \n",
    "# output_of_network = feed_forward(a, weights, biases)\n",
    "# desired_output = np.ones(output_of_network.shape)\n",
    "# \n",
    "# z = np.subtract(desired_output,output_of_network)**2\n",
    "# \n",
    "# print(z)\n",
    "# \n",
    "# cost = (1.0/practice[-1]) * sum(z)\n",
    "# \n",
    "# \n",
    "# print(\"Output Matrix\", output_of_network)\n",
    "# \n",
    "# print(\"Cost of matrix\", cost)\n",
    "\n",
    "predicted_ouput, activations = feed_forward(a, weights, biases)\n",
    "\n",
    "print(\"Activations: \", activations)\n",
    "print(\"Final Output: \", predicted_ouput)\n",
    "print(create_error_matrix(weights,[1],predicted_ouput))\n",
    "\n",
    "\n",
    "\n",
    "cost = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}