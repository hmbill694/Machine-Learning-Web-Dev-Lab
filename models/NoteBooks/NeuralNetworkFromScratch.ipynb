{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_sklearn_to_data_frame(in_data_set):\n",
    "    data_set = in_data_set\n",
    "    df = pd.DataFrame(data_set.data,columns=data_set.feature_names)\n",
    "    df[\"target\"] = pd.Series(data_set.target)\n",
    "    return df\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"This is the activation function for the network, it will\n",
    "        squishify the results of the network to be between 0 and 1.\n",
    "        It is non-linear  like all other activation functions\"\"\"\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"This is the \"derivative\" of the sigmoid function. \n",
    "        it will be used in the learning phase of the network. \n",
    "        The real derivative of the sigmoid function is\n",
    "        f'(x) = sigmoid(x) x (1- sigmoid(x)). However\n",
    "        when using this in the program my values have already\n",
    "        gone through the sigmoid function so doing so again would be\n",
    "        incorrect\"\"\"\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "\n",
    "def create_weight_matrix_for_layer(num_neurons_in_next_layer,\n",
    "                                   num_neurons_in_current_layer):\n",
    "    \"\"\"This will create a matrix with random values of the shape \n",
    "        R x C where R = the number of neurons in the next layer\n",
    "        and C = the number of neurons in the current layer\"\"\"\n",
    "\n",
    "    return np.random.randn(num_neurons_in_next_layer,num_neurons_in_current_layer)\n",
    "\n",
    "def create_weight_matrix_for_network(network_architecture):\n",
    "    \"\"\"This function will create the weight matrix for an entire network\n",
    "        it takes a list where each member in the list represents the the number\n",
    "        of neurons in that layer. So a input of [5,2,1] represents a network\n",
    "        with 5 neurons in the first layer, 2 in the second and one in the last layer.\n",
    "        It will return a list of n-dimensional numpy arrays where each entry in the list\n",
    "        represents the weights from one layer to the next\"\"\"\n",
    "    \n",
    "    # Okay so what's this slicing about? For the architecture of a network we are able to \n",
    "    # deduce the overall structure of the weight matrix. We will have n-1 weight layers \n",
    "    # per network where n is the total number of network layers. There are no weights for \n",
    "    # incoming data so a network shaped like [5,2,1] will have 2 weight layers. \n",
    "    # The first weight layer will be an array with two rows and 5 columns, the second\n",
    "    # 1 row with 2 columns\n",
    "    column_values = network_architecture[:-1]\n",
    "    row_values = network_architecture[1:]\n",
    "    \n",
    "    return [create_weight_matrix_for_layer(row,col) for row, col in zip(row_values, column_values)]\n",
    "\n",
    "def create_biases_for_layer(num_neurons_in_layer):\n",
    "    \"\"\"Creates a np matrix of (n x 1) for a layer of a network\n",
    "        returns the matrix \"\"\"\n",
    "    return np.random.randn(num_neurons_in_layer,1)\n",
    "\n",
    "def create_bias_matrix_for_network(network_architecture):\n",
    "    \"\"\"The number of bias matrices for a network is n - 1, where\n",
    "        no is the number of layers in the network, including inputs.\n",
    "        Each neuron in a layer will have it's own bias. So a network \n",
    "        of size [5,2,1] will have two biases for one layer and 1 for the next.\n",
    "        The inputs do not get biases.\"\"\"\n",
    "    layers_that_need_biases = network_architecture[1:]\n",
    "    return [create_biases_for_layer(neurons_in_layer) for neurons_in_layer in layers_that_need_biases ]\n",
    "    \n",
    "\n",
    "def back_propagate_error(weight_matrix, actual_values_matrix, guessed_values_matrix):\n",
    "    \"\"\"This function will calculate a error matrix for each hidden layer neuron \"\"\"\n",
    "    actual_values_matrix = np.c_[actual_values_matrix]\n",
    "    guessed_values_matrix = np.c_[guessed_values_matrix]\n",
    "    \n",
    "    # seed error with error between output of network and target output \n",
    "    error = [np.subtract(actual_values_matrix, guessed_values_matrix)]\n",
    "    \n",
    "    # Reverse the weight matrix and then iterate in reverse to\n",
    "    # the last layer, we omit the first layer as that would calculate \n",
    "    # the error for inputs which does not make sense\n",
    "    for index, layer in enumerate(weight_matrix[:0:-1]):\n",
    "        error.append(np.dot(layer.transpose(), error[index]))\n",
    "    return list(reversed(error))\n",
    "\n",
    "def create_deltas(learning_rate,weight_matrix, bias_matrix, error_matrix, activations):\n",
    "    \"\"\"This method will find the changes to each of the weights and biases in the network \n",
    "        it will then return these two lists of deltas\"\"\"\n",
    "    \n",
    "    #lambda function to apply the derivative of sigmoid to the activations array\n",
    "    vectorized_sigmoid_prime = lambda x : sigmoid_prime(x)\n",
    "    \n",
    "    #lists to contain the delta for each layer's weights and biases\n",
    "    delta_weights = []\n",
    "    delta_biases = []\n",
    "    \n",
    "    # the gradients found from applying the sigmoid prime to the activations, omitting the first layer\n",
    "    # which is the inputs, these cannot be altered\n",
    "    gradients = [vectorized_sigmoid_prime(layer) for layer in activations[1:]]\n",
    "    \n",
    "    # iterate over the errors, gradients, weights, biases, and activations\n",
    "    # applying the function delta_wieght_layer = Gradient * lr * Error Layer * activation.T\n",
    "    # the delta_biases = gradients for that layer\n",
    "    for _,error_layer,gradient,activation,bias in zip(weight_matrix,error_matrix, gradients,activations, bias_matrix):\n",
    "        gradient = np.multiply(gradient, learning_rate)\n",
    "        gradient = np.multiply(gradient, error_layer)\n",
    "        delta_layer = np.multiply(activation.transpose(), gradient)\n",
    "        delta_weights.append(delta_layer)\n",
    "        delta_biases.append(gradient)\n",
    "    \n",
    "    #return lists of gathered errors\n",
    "    return delta_weights, delta_biases\n",
    "\n",
    "def train_SGD(learning_rate, input_pairs, weight_matrix, bias_matrix, iterations):\n",
    "    \"\"\"This method will uses stochastic gradient descent to train the network. It will \n",
    "        select a random entry in the input_pairs, which is tuple of lists where [0]: inputs\n",
    "        and where [1]: 1 is the known answer. It will then return the adjusted weights and biases\n",
    "        for the network after executing the training loop for the number of iterations\"\"\"\n",
    "    \n",
    "    # training loop for SGD \n",
    "    for x in range(iterations):\n",
    "        test_item_pair = random.choice(input_pairs)\n",
    "        known_output = test_item_pair[1]\n",
    "        predicted_output, activations = feed_forward(test_item_pair[0],weight_matrix,bias_matrix)\n",
    "        error_matrix = back_propagate_error(weight_matrix,known_output,predicted_output)\n",
    "        delta_weight_matrix, delta_biases_matrix = create_deltas(learning_rate, weight_matrix, \n",
    "                                                                 bias_matrix, error_matrix, activations)\n",
    "        # adjust weights and biases by delta for the layer\n",
    "        weight_matrix = np.add(weight_matrix,delta_weight_matrix)\n",
    "        bias_matrix = np.add(bias_matrix,delta_biases_matrix)\n",
    "    \n",
    "    # adjusted weights and biases for network\n",
    "    return  weight_matrix, bias_matrix\n",
    "        \n",
    "def feed_forward(input_matrix_as_list, network_weight_matrix, network_bias_matrix,guess=False):\n",
    "    \"\"\"This function feeds the inputs into the matrix.\"\"\"\n",
    "    # Store inputs as a column matrix (n x 1)\n",
    "    if isinstance(input_matrix_as_list, (np.ndarray, np.generic) ):\n",
    "        input_matrix_as_list = input_matrix_as_list.tolist()\n",
    "        \n",
    "    output = np.c_[input_matrix_as_list]\n",
    "    layer_activations = [output]\n",
    "    \n",
    "    for bias, weight in zip(network_bias_matrix, network_weight_matrix):\n",
    "        output = sigmoid(np.dot(weight,output ) + bias)\n",
    "        layer_activations.append(output)\n",
    "    \n",
    "    if not guess:\n",
    "        return output, layer_activations\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.0187507]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "xor_inputs = [[1, 1], [1, 0], [0, 1], [0, 0]]\n",
    "xor_answers = [[0], [1], [1], [0]]\n",
    "\n",
    "pair_list = [(x,y) for x, y in zip(xor_inputs, xor_answers)]\n",
    "arch = [2,2,1]\n",
    "\n",
    "weights = create_weight_matrix_for_network(arch)\n",
    "biases = create_bias_matrix_for_network(arch)\n",
    "\n",
    "weights, biases = train_SGD(.01,pair_list,weights,biases,500000)\n",
    "\n",
    "guess = feed_forward([0,0], weights,biases,guess=True)\n",
    "\n",
    "print(guess)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}